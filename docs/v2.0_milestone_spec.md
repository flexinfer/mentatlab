\n# MentatLab v2.0 Milestone Technical Specification\n## Advanced Observability & Cost Metering Platform\n\n**Timeline**: Q3 2026 (16 weeks)  \n**Dependencies**: v1.1 completion (Agent marketplace, enhanced mentatctl)\n\n---\n\n## Executive Summary\n\nThis specification outlines the technical implementation for MentatLab's v2.0 milestone, introducing enterprise-grade observability and cost transparency:\n\n1. **Distributed Tracing System**: OpenTelemetry-based tracing with cross-agent correlation\n2. **Cost Metering Dashboard**: Accurate resource attribution and billing integration\n3. **Real-time Monitoring**: Comprehensive metrics with custom dashboards and alerting\n4. **Performance Profiling**: Bottleneck identification and optimization recommendations\n5. **Enterprise Analytics**: Advanced reporting and capacity planning platform\n\nBuilding upon v1.1's marketplace and developer tools, v2.0 establishes MentatLab as an enterprise-ready platform with comprehensive visibility into agent execution, performance, and costs.\n\n---\n\n## 1. Distributed Tracing Architecture\n\n### 1.1 OpenTelemetry Integration\n\n```yaml\n# Core components for distributed tracing\ncomponents:\n  collectors:\n    type: OpenTelemetry Collector\n    deployment: DaemonSet\n    config:\n      receivers:\n        - otlp/grpc (4317)\n        - otlp/http (4318)\n        - jaeger (14250)\n      processors:\n        - batch\n        - memory_limiter\n        - resource_detection\n        - span_metrics\n      exporters:\n        - jaeger\n        - prometheus\n        - kafka (for streaming)\n  \n  storage:\n    primary: Jaeger with Elasticsearch backend\n    retention: 30 days hot, 90 days cold\n    sampling: Adaptive (1-100% based on error rate)\n```\n\n### 1.2 Trace Context Propagation\n\n```python\n# SDK enhancement for trace propagation\nclass MentatAgent:\n    def __init__(self):\n        self.tracer = trace.get_tracer(__name__)\n        \n    async def process(self, input: Input, context: TraceContext):\n        \"\"\"Process with distributed tracing\"\"\"\n        # Extract parent trace context\n        parent_ctx = extract(context.headers, propagators.get())\n        \n        with self.tracer.start_as_current_span(\n            f\"{self.agent_id}.process\",\n            context=parent_ctx,\n            kind=SpanKind.SERVER\n        ) as span:\n            # Add agent metadata\n            span.set_attribute(\"agent.id\", self.agent_id)\n            span.set_attribute(\"agent.version\", self.version)\n            span.set_attribute(\"agent.runtime\", self.runtime)\n            span.set_attribute(\"flow.id\", context.flow_id)\n            span.set_attribute(\"flow.run_id\", context.run_id)\n            \n            # Process and propagate context\n            output_headers = {}\n            inject(output_headers, propagators.get())\n            \n            return await self._process_internal(input), output_headers\n```\n\n### 1.3 Cross-Runtime Correlation\n\n```typescript\n// Trace correlation across WASM and container agents\ninterface TraceCorrelator {\n  // Correlate traces across different execution modes\n  correlate(traces: Trace[]): CorrelatedFlow {\n    const flowMap = new Map<string, FlowTrace>();\n    \n    traces.forEach(trace => {\n      const flowId = trace.attributes['flow.id'];\n      const runId = trace.attributes['flow.run_id'];\n      const key = `${flowId}:${runId}`;\n      \n      if (!flowMap.has(key)) {\n        flowMap.set(key, {\n          flowId,\n          runId,\n          spans: [],\n          criticalPath: null\n        });\n      }\n      \n      flowMap.get(key).spans.push(...trace.spans);\n    });\n    \n    // Calculate critical path for each flow\n    flowMap.forEach((flow, key) => {\n      flow.criticalPath = this.calculateCriticalPath(flow.spans);\n    });\n    \n    return flowMap;\n  }\n}\n```\n\n### 1.4 Trace Visualization\n\n```mermaid\ngraph LR\n    subgraph Flow Execution Trace\n        A[User Request] --> B[Gateway]\n        B --> C[Orchestrator]\n        C --> D[Agent 1 - WASM]\n        C --> E[Agent 2 - Container]\n        D --> F[Agent 3 - Container]\n        E --> F\n        F --> G[Response]\n    end\n    \n    subgraph Trace Metadata\n        H[Flow ID: abc123]\n        I[Run ID: xyz789]\n        J[Total Duration: 1.2s]\n        K[Critical Path: A→B→C→D→F→G]\n    end\n```\n\n---\n\n## 2. Cost Metering System\n\n### 2.1 Resource Attribution Model\n\n```python\n# Comprehensive cost tracking model\nclass ResourceMeter:\n    \"\"\"Track resource usage at multiple granularities\"\"\"\n    \n    def __init__(self):\n        self.meters = {\n            'cpu': CPUMeter(),\n            'memory': MemoryMeter(),\n            'gpu': GPUMeter(),\n            'network': NetworkMeter(),\n            'storage': StorageMeter(),\n            'tokens': TokenMeter()\n        }\n    \n    async def measure_agent_execution(\n        self, \n        agent_id: str,\n        execution_context: ExecutionContext\n    ) -> ResourceUsage:\n        \"\"\"Measure resource usage for a single agent execution\"\"\"\n        \n        usage = ResourceUsage(\n            agent_id=agent_id,\n            flow_id=execution_context.flow_id,\n            run_id=execution_context.run_id,\n            user_id=execution_context.user_id,\n            project_id=execution_context.project_id,\n            start_time=datetime.utcnow()\n        )\n        \n        # Start resource monitoring\n        with self.meters.measure_all() as measurements:\n            yield  # Agent executes here\n            \n        # Collect measurements\n        usage.end_time = datetime.utcnow()\n        usage.duration_ms = (usage.end_time - usage.start_time).total_seconds() * 1000\n        \n        # Resource measurements\n        usage.cpu_core_seconds = measurements['cpu'].core_seconds\n        usage.memory_gb_seconds = measurements['memory'].gb_seconds\n        usage.gpu_seconds = measurements['gpu'].seconds if measurements['gpu'] else 0\n        usage.network_bytes = measurements['network'].total_bytes\n        usage.storage_bytes = measurements['storage'].bytes_used\n        \n        # Model-specific measurements\n        usage.tokens_input = measurements['tokens'].input_count\n        usage.tokens_output = measurements['tokens'].output_count\n        usage.model_name = measurements['tokens'].model_name\n        \n        return usage\n```\n\n### 2.2 Cost Calculation Engine\n\n```python\n# Dynamic cost calculation with resource pricing\nclass CostCalculator:\n    def __init__(self, pricing_config: PricingConfig):\n        self.pricing = pricing_config\n        \n    def calculate_cost(self, usage: ResourceUsage) -> CostBreakdown:\n        \"\"\"Calculate detailed cost breakdown\"\"\"\n        \n        breakdown = CostBreakdown()\n        \n        # Compute costs\n        breakdown.cpu_cost = (\n            usage.cpu_core_seconds * self.pricing.cpu_per_core_hour / 3600\n        )\n        breakdown.memory_cost = (\n            usage.memory_gb_seconds * self.pricing.memory_per_gb_hour / 3600\n        )\n        breakdown.gpu_cost = (\n            usage.gpu_seconds * self.pricing.gpu_per_hour / 3600\n        )\n        breakdown.network_cost = (\n            usage.network_bytes * self.pricing.network_per_gb / (1024**3)\n        )\n        breakdown.storage_cost = (\n            usage.storage_bytes * self.pricing.storage_per_gb_month / (1024**3 * 30 * 24 * 3600)\n        )\n        \n        # Token costs (model-specific)\n        model_pricing = self.pricing.models.get(usage.model_name, {})\n        breakdown.token_cost = (\n            usage.tokens_input * model_pricing.get('input_per_1k', 0) / 1000 +\n            usage.tokens_output * model_pricing.get('output_per_1k', 0) / 1000\n        )\n        \n        # Apply markups and discounts\n        breakdown.subtotal = sum([\n            breakdown.cpu_cost,\n            breakdown.memory_cost,\n            breakdown.gpu_cost,\n            breakdown.network_cost,\n            breakdown.storage_cost,\n            breakdown.token_cost\n        ])\n        \n        # Volume discounts\n        discount_rate = self.get_volume_discount(usage.user_id)\n        breakdown.discount = breakdown.subtotal * discount_rate\n        \n        breakdown.total = breakdown.subtotal - breakdown.discount\n        \n        return breakdown\n```\n\n### 2.3 Cost Aggregation Service\n\n```python\n# Hierarchical cost aggregation\nclass CostAggregator:\n    async def aggregate_costs(\n        self,\n        time_range: TimeRange,\n        grouping: List[str]  # e.g., ['user_id', 'project_id', 'agent_id']\n    ) -> AggregatedCosts:\n        \"\"\"Aggregate costs by multiple dimensions\"\"\"\n        \n        # Query raw usage data\n        usage_records = await self.query_usage_records(time_range)\n        \n        # Build aggregation tree\n        aggregation_tree = {}\n        \n        for record in usage_records:\n            # Navigate/create path in tree\n            current = aggregation_tree\n            for group_key in grouping[:-1]:\n                group_value = getattr(record, group_key)\n                if group_value not in current:\n                    current[group_value] = {}\n                current = current[group_value]\n            \n            # Aggregate at leaf level\n            final_key = getattr(record, grouping[-1])\n            if final_key not in current:\n                current[final_key] = CostSummary()\n            \n            current[final_key].add(record)\n        \n        return AggregatedCosts(\n            tree=aggregation_tree,\n            grouping=grouping,\n            time_range=time_range,\n            total=self._calculate_total(aggregation_tree)\n        )\n```\n\n### 2.4 Billing Integration\n\n```python\n# Enterprise billing system integration\nclass BillingIntegration:\n    def __init__(self):\n        self.adapters = {\n            'stripe': StripeAdapter(),\n            'aws_marketplace': AWSMarketplaceAdapter(),\n            'custom_erp': CustomERPAdapter()\n        }\n    \n    async def sync_usage_to_billing(\n        self,\n        billing_period: BillingPeriod\n    ):\n        \"\"\"Sync aggregated usage to billing systems\"\"\"\n        \n        # Get aggregated costs by customer\n        costs = await self.cost_aggregator.aggregate_costs(\n            time_range=billing_period.to_time_range(),\n            grouping=['customer_id', 'subscription_id']\n        )\n        \n        # Transform to billing format\n        for customer_id, subscriptions in costs.tree.items():\n            customer = await self.get_customer(customer_id)\n            \n            for subscription_id, cost_summary in subscriptions.items():\n                # Create usage record\n                usage_record = UsageRecord(\n                    customer_id=customer_id,\n                    subscription_id=subscription_id,\n                    period_start=billing_period.start,\n                    period_end=billing_period.end,\n                    line_items=self._create_line_items(cost_summary),\n                    total_amount=cost_summary.total,\n                    currency='USD'\n                )\n                \n                # Send to billing system\n                adapter = self.adapters[customer.billing_provider]\n                await adapter.report_usage(usage_record)\n```\n\n---\n\n## 3. Real-time Monitoring Dashboard\n\n### 3.1 Metrics Collection Architecture\n\n```yaml\n# Prometheus-based metrics collection\nmonitoring:\n  prometheus:\n    retention: 15d\n    scrape_interval: 15s\n    federation:\n      enabled: true\n    